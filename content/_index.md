<!-- logo image -->
<img src="/images/logo.jpg" alt="Computational Musicology SIG Logo" style="display:block; margin:1.5rem auto; width:100%; max-width:400px; height:auto;"> 

<h1 class="main-title">Computational Musicology SIG</h1>
<h2 class="main-title">An MTG Community on Computational Musicology and Music Understanding</h2>



Welcome to the **Computational Musicology Special Interest Group (SIG)** at the [Music Technology Group (MTG)](https://www.upf.edu/web/mtg), Universitat Pompeu Fabra, Barcelona.  

The SIG brings together researchers and students exploring computational approaches to (ethno-)musicology, spanning topics such as symbolic and audio analysis, and music understanding.

We meet monthly on **Fridays at 3 p.m.** for seminars in which **invited speakers** share their latest work and engage in open discussions with the MTG community. Sessions are held online via Zoom and are open to everyone. 

<div class="link-grid">
  <a href="https://zoom.us/j/your-zoom-linkhttps://upf-edu.zoom.us/j/94354379156" class="link-card">
    <span class="emoji">💻</span> Join on Zoom
  </a>
  <a href="https://www.youtube.com/playlist?list=YOUR_PLAYLIST_ID" class="link-card">
    <span class="emoji">🎥</span> YouTube Recordings
  </a>
  <a href="https://your-newsletter-linkhttps://groups.google.com/u/3/a/llista.upf.edu/g/mtg-sig-compmusic/about" class="link-card">
    <span class="emoji">📬</span> Newsletter
  </a>
</div>

---

<h1 style="text-align:center">Upcoming Events</h1>

<hr class="talk-divider">

Talks for the fall/winter 2025-2026 will be announced soon.

---

<h1 style="text-align:center">Past Events</h1>

<hr class="talk-divider">

### 🗓️ 18 July 2025  
<div class="speaker-line">
  <strong>Speaker:</strong> Yash Bhake <em>(IIT Bombay)</em>
  <a href="https://www.linkedin.com/in/yashbhake/" class="link-card small">🔗 LinkedIn</a>
  <a href="https://scholar.google.comhttps://scholar.google.com/citations?user=8V42R8kAAAAJ&hl=en" class="link-card small">🎓 Scholar</a>
</div>

**Title:** *Melodic and Metrical Elements of Expression in Hindustani Vocal Music*

<details>
  <summary><b>📄 Abstract</b></summary>
  <p>
  This work presents an attempt to study the aesthetics of North Indian Khayal music with reference to the flexibility exercised by artists in performing popular compositions.
  We study expressive timing and pitch variations of the given lyrical content within and across performances and propose computational representations that can discriminate between different performances of the same song in terms of expression.
  We present the necessary audio processing and annotation procedures, and discuss our observations and insights from the analysis of a dataset of two songs in two ragas each rendered by ten prominent artists.
  </p>
</details>

<div class="link-grid">
  <a href="https://youtube.com" target="_blank" class="link-card">🎥 Recording</a>
  <a href="https://your-slides-link" target="_blank" class="link-card">📑 Slides</a>
</div>

<hr class="talk-divider">

### 🗓️ 6 June 2025  
<div class="speaker-line">
  <strong>Speaker:</strong> Marius Miron <em>(Earth Species Project)</em>
  <a href="https://es.linkedin.com/in/marius-miron-9473233" class="link-card small">🔗 LinkedIn</a>
  <a href="https://scholar.google.com/citations?user=enIrFKEAAAAJ&hl=en" class="link-card small">🎓 Scholar</a>
</div>

**Title:** *Source separation without ground-truth data*

<details>
  <summary><b>📄 Abstract</b></summary>
  <p>
  Far from being a solved problem, deep learning source separation has reached impressive performance, particularly on Western pop-rock music. Formalising the task as a 4-stem separation problem—alongside open baselines, datasets, and public challenges—has driven significant methodological progress. However, the task remains challenging in non-standard setups, such as variable instrumentations, non-Western genres, universal source separation, and bioacoustics, where clean reference data is often unavailable.
  This talk will explore several strategies to address this issue, including domain adaptation, self-training, and knowledge distillation, and will present a practical case: denoising animal vocalisations.
  </p>
</details>

<div class="link-grid">
  <a href="https://youtube.com" target="_blank" class="link-card">🎥 Recording</a>
  <a href="https://your-slides-link" target="_blank" class="link-card">📑 Slides</a>
</div>

<hr class="talk-divider">

### 🗓️ 23 May 2025  
<div class="speaker-line">
  <strong>Speaker:</strong> Rafael Caro Repetto <em>(Institute of Digital Sciences Austria)</em>
  <a href="https://www.linkedin.com/in/rafaelcarorepetto" class="link-card small">🔗 LinkedIn</a>
  <a href="https://scholar.google.es/citations?user=_M1UwW4AAAAJ&hl=en" class="link-card small">🎓 Scholar</a>
</div>

**Title:** *Computational methods for ethnomusicology: possibilities and challenges*

<div class="link-grid">
  <a href="https://drive.google.com/file/d/1V1Ev-6r-a9jzoeydIa0-KNohInplQ04V/view?usp=sharing" target="_blank" class="link-card">📑 Slides</a>
</div>