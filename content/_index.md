<!-- logo image -->
<img src="/computational-musicology/images/logo.jpg" alt="Computational Musicology SIG Logo" style="display:block; margin:1.5rem auto; width:100%; max-width:400px; height:auto;"> 

<h1 class="main-title">Computational Musicology SIG</h1>
<h2 class="main-title">An MTG Community on Computational Musicology and Music Understanding</h2>



Welcome to the **Computational Musicology Special Interest Group (SIG)** at the [Music Technology Group (MTG)](https://www.upf.edu/web/mtg), Universitat Pompeu Fabra, Barcelona.  

The SIG brings together researchers and students exploring computational approaches to (ethno-)musicology, spanning topics such as symbolic and audio analysis, and music understanding.

We meet monthly on **Fridays at 3 p.m.** for seminars in which **invited speakers** share their latest work and engage in open discussions with the MTG community. Sessions are held online via Zoom and are open to everyone. 

<div class="link-grid">
  <a href="https://upf-edu.zoom.us/j/94354379156" class="link-card">
    <span class="emoji">ğŸ’»</span> Join on Zoom
  </a>
  <a href="https://www.youtube.com/@MusicTechnologyGroup" class="link-card">
    <span class="emoji">ğŸ¥</span> YouTube Recordings
  </a>
  <a href="https://groups.google.com/u/3/a/llista.upf.edu/g/mtg-sig-compmusic/about" class="link-card">
    <span class="emoji">ğŸ“¬</span> Newsletter
  </a>
</div>

---

<h1 style="text-align:center">Upcoming Events</h1>

<hr class="talk-divider">

### ğŸ—“ï¸ 7 November 2025  
<div class="speaker-line">
  <strong>Speaker:</strong> Mark Gotham <em>(King's College London)</em>
  <a href="https://markgotham.github.io/" class="link-card small">ğŸŒ Website</a>
  <a href="https://uk.linkedin.com/in/mark-gotham-66127444" class="link-card small">ğŸ”— LinkedIn</a>
  <a href="https://scholar.google.com/citations?user=bA0PEo0AAAAJ&hl=en" class="link-card small">ğŸ“ Scholar</a>
</div>

**Title:** *Cultivating Communities for Cumulative Science, Within and Beyond MIR*

<details>
  <summary><b>ğŸ“„ Abstract</b></summary>
  <p>
  While research is sometimes a solitary pursuit, most recognise that deep, field-wide collaboration is the best way to advance the field most effectively. And while MIR â€“ like all fields â€“ faces certain challenges, overall, it is a wonderfully open and engaged community that is highly responsive to this best practice and keen to build each other up for the collective good. This is a key strength to build on.

  In this talk, I will share frank experiences from some major, long-term and highly collaborative projects including the â€œOpenScore" transcription effort (in collaboration with the commercial company Musescore.com and a large number of community volunteers), the "Open Music Theoryâ€ textbook (http://viva.pressbooks.pub/openmusictheory/), the social initiative "Four Score and More" (https://fourscoreandmore.org/), and a nascent effort to coordinate a wide range of Algorithms for Music Analysis and Data Science ("AMADS, https://github.com/music-computing/amads/).
  </p>
</details>

<hr class="talk-divider">

### ğŸ—“ï¸ 28 November 2025  
<div class="speaker-line">
  <strong>Speaker:</strong> Christof WeiÃŸ <em>(UniversitÃ¤t WÃ¼rzburg)</em>
  <a href="https://www.christofweiss.com/" class="link-card small">ğŸŒ Website</a>
  <a href="https://www.linkedin.com/in/christof-wei%C3%9F-57879866/" class="link-card small">ğŸ”— LinkedIn</a>
  <a href="https://scholar.google.com/citations?user=i6nx0CsAAAAJ&hl=de" class="link-card small">ğŸ“ Scholar</a>
</div>

**Title:** *Computational Analysis of Music Audio Recordings: Corpora, Concepts, and Algorithms*

<hr class="talk-divider">

### ğŸ—“ï¸ 05 December 2025  
<div class="speaker-line">
  <strong>Speaker:</strong> Peter Peter Van Kranenburg <em>(Utrecht University)</em>
  <a href="https://nl.linkedin.com/in/pvankranenburg" class="link-card small">ğŸ”— LinkedIn</a>
  <a href="https://scholar.google.com/citations?user=F74qwNQAAAAJ&hl=en" class="link-card small">ğŸ“ Scholar</a>
</div>

<hr class="talk-divider">


### ğŸ—“ï¸ 12 December 2025  
<div class="speaker-line">
  <strong>Speaker:</strong> David Dalmazzo <em>(Universitat Pompeu Fabra)</em>
  <a href="https://dazzid.github.io/ANIMA_Harmonic_Eigenspace/" class="link-card small">ğŸŒ Website</a>
  <a href="https://es.linkedin.com/in/dazzid" class="link-card small">ğŸ”— LinkedIn</a>
  <a href="https://scholar.google.com/citations?user=F74qwNQAAAAJ&hl=en" class="link-card small">ğŸ“ Scholar</a>
</div>

**Title:** *Harmonic modeling in microtonality*

<hr class="talk-divider">

### ğŸ—“ï¸ 23 January 2026  
<div class="speaker-line">
  <strong>Speaker:</strong> Lara Pearson <em>(University of Cologne)</em>
  <a href="https://musikwissenschaft.phil-fak.uni-koeln.de/en/staff/professors/lara-pearson" class="link-card small">ğŸŒ Website</a>
  <a href="https://scholar.google.com/citations?user=Y4jdiz8AAAAJ&hl=en" class="link-card small">ğŸ“ Scholar</a>
  <br>
  <strong>and</strong> Thomas Nuttall <em>(Universitat Pompeu Fabra)</em>
  <a href="https://thomasgnuttall.github.io/about/" class="link-card small">ğŸŒ Website</a>
  <a href="https://scholar.google.com/citations?user=11bIYxsAAAAJ&hl=en&authuser=1" class="link-card small">ğŸ“ Scholar</a>
</div>
<hr class="talk-divider">

### ğŸ—“ï¸ 06 February 2026  
<div class="speaker-line">
  <strong>Speaker:</strong> Jan HajiÄ <em>(Charles University)</em>
  <a href="https://ufal.mff.cuni.cz/jan-hajic-jr" class="link-card small">ğŸŒ Website</a>
  <a href="https://cz.linkedin.com/in/jan-haji%C4%8D-jr-4b8a81bb" class="link-card small">ğŸ”— LinkedIn</a>
  <a href="https://scholar.google.com/citations?user=1CWcwO0AAAAJ&hl=en" class="link-card small">ğŸ“ Scholar</a>
</div>
<hr class="talk-divider">


### ğŸ—“ï¸ 13 February 2026  
<div class="speaker-line">
  <strong>Speaker:</strong> Ken DÃ©guernel <em>(CNRS)</em>
  <a href="https://deguernel.discordia.fr/" class="link-card small">ğŸŒ Website</a>
  <a href="https://scholar.google.com/citations?user=OhFS_ZEAAAAJ&hl=fr" class="link-card small">ğŸ“ Scholar</a>
</div>


---

<h1 style="text-align:center">Past Events</h1>

<hr class="talk-divider">

### ğŸ—“ï¸ 18 July 2025  
<div class="speaker-line">
  <strong>Speaker:</strong> Yash Bhake <em>(IIT Bombay)</em>
  <a href="https://www.linkedin.com/in/yashbhake/" class="link-card small">ğŸ”— LinkedIn</a>
  <a href="https://scholar.google.comhttps://scholar.google.com/citations?user=8V42R8kAAAAJ&hl=en" class="link-card small">ğŸ“ Scholar</a>
</div>

**Title:** *Melodic and Metrical Elements of Expression in Hindustani Vocal Music*

<details>
  <summary><b>ğŸ“„ Abstract</b></summary>
  <p>
  This work presents an attempt to study the aesthetics of North Indian Khayal music with reference to the flexibility exercised by artists in performing popular compositions.
  We study expressive timing and pitch variations of the given lyrical content within and across performances and propose computational representations that can discriminate between different performances of the same song in terms of expression.
  We present the necessary audio processing and annotation procedures, and discuss our observations and insights from the analysis of a dataset of two songs in two ragas each rendered by ten prominent artists.
  </p>
</details>

<div class="link-grid">
  <a href="https://www.youtube.com/watch?v=R2kWpK7UGwY" target="_blank" class="link-card">ğŸ¥ Recording</a>
  <!-- <a href="#" target="_blank" class="link-card">ğŸ“‘ Slides</a> -->
</div>

<hr class="talk-divider">

### ğŸ—“ï¸ 6 June 2025  
<div class="speaker-line">
  <strong>Speaker:</strong> Marius Miron <em>(Earth Species Project)</em>
  <a href="https://es.linkedin.com/in/marius-miron-9473233" class="link-card small">ğŸ”— LinkedIn</a>
  <a href="https://scholar.google.com/citations?user=enIrFKEAAAAJ&hl=en" class="link-card small">ğŸ“ Scholar</a>
</div>

**Title:** *Source separation without ground-truth data*

<details>
  <summary><b>ğŸ“„ Abstract</b></summary>
  <p>
  Far from being a solved problem, deep learning source separation has reached impressive performance, particularly on Western pop-rock music. Formalising the task as a 4-stem separation problemâ€”alongside open baselines, datasets, and public challengesâ€”has driven significant methodological progress. However, the task remains challenging in non-standard setups, such as variable instrumentations, non-Western genres, universal source separation, and bioacoustics, where clean reference data is often unavailable.
  This talk will explore several strategies to address this issue, including domain adaptation, self-training, and knowledge distillation, and will present a practical case: denoising animal vocalisations.
  </p>
</details>

<div class="link-grid">
  <a href="https://www.youtube.com/watch?v=Njih0EXYJsk" target="_blank" class="link-card">ğŸ¥ Recording</a>
  <!-- <a href="#" target="_blank" class="link-card">ğŸ“‘ Slides</a> -->
</div>

<hr class="talk-divider">

### ğŸ—“ï¸ 23 May 2025  
<div class="speaker-line">
  <strong>Speaker:</strong> Rafael Caro Repetto <em>(Institute of Digital Sciences Austria)</em>
  <a href="https://www.linkedin.com/in/rafaelcarorepetto" class="link-card small">ğŸ”— LinkedIn</a>
  <a href="https://scholar.google.es/citations?user=_M1UwW4AAAAJ&hl=en" class="link-card small">ğŸ“ Scholar</a>
</div>

**Title:** *Computational methods for ethnomusicology: possibilities and challenges*

<div class="link-grid">
  <a href="https://drive.google.com/file/d/1V1Ev-6r-a9jzoeydIa0-KNohInplQ04V/view?usp=sharing" target="_blank" class="link-card">ğŸ“‘ Slides</a>
</div>